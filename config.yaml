# Podcast Reels Forge Configuration

paths:
  input_dir: "input"
  output_dir: "output"

cli:
  quiet: false
  verbose: false

# Cache / stage skipping
# When enabled, stages are skipped if their expected output files already exist.
cache:
  enabled: true
  validate_json: true

transcription:
  model: "medium"        # tiny, base, small, medium, large-v3
  device: "cuda"         # cuda | cpu | auto
  language: "ru"         # "ru", "en", or "auto"
  beam_size: 5
  compute_type: "float32"  # float32|float16|int8|int8_float16|int8_float32|auto

ollama:
  url: "http://127.0.0.1:11434/api/generate"
  # Only these models are supported by default.
  # Each one will run analysis into its own folder under output/.
  models:
    - "qwen3:latest"
    - "deepseek-r1:8b"
    - "gemma3:4b"
    - "gemma2:9b"
    - "gemini-3-flash-preview:latest"
  # Hard timeout per LLM call (per chunk). Keep this bounded to avoid multi-hour runs.
  timeout: 240
  temperature: 0.3
  # Larger chunks = fewer LLM calls overall (usually faster end-to-end).
  chunk_seconds: 1200
  max_chars_chunk: 12000
  # Watchdog: detects stalls/very slow generation and retries.
  watchdog:
    enabled: true
    first_token_timeout: 45   # seconds without any output
    stall_timeout: 60         # seconds without output during streaming
    log_interval: 10          # progress heartbeat interval (sec)
    max_retries: 0
  # Optional: try these models in order if the current model stalls.
  fallback_models: []

  # Per-model overrides to keep gemma3/gemini3 fast, while allowing heavier/slower
  # models enough warmup time to start generating.
  model_overrides:
    qwen3:latest:
      timeout: 900
      chunk_seconds: 600
      watchdog:
        first_token_timeout: 180
        stall_timeout: 120
        max_retries: 1
    deepseek-r1:8b:
      timeout: 900
      chunk_seconds: 600
      watchdog:
        first_token_timeout: 180
        stall_timeout: 120
        max_retries: 1
    gemma2:9b:
      timeout: 600
      chunk_seconds: 600
      watchdog:
        first_token_timeout: 90
        stall_timeout: 120

prompts:
  language: "ru"          # ru|en
  variant: "default"      # A/B testing: default|a|b

processing:
  # Counts and duration limits for different clip types
  clips:
    stories:
      count: 2
      max_duration: 15
    reels:
      count: 3
      max_duration: 60
    long_reels:
      count: 1
      max_duration: 180
    highlights:
      count: 1           # Number of highlight videos to create (usually 1)
      moments_count: 5    # Number of hot moments inside the highlights video

  reels_count: 4          # [Legacy/Default] Total number of clips if 'clips' is not used
  reel_min_duration: 30    # Minimum reel length (seconds)
  reel_max_duration: 60    # Maximum reel length (seconds)
  reel_padding: 5         # Extra seconds around the moment (5s before + 5s after)

exports:
  webm: false
  gif: false
  audio_only: false

video:
  threads: 4
  vertical_crop: true      # Crop 16:9 to 9:16 automatically
  video_bitrate: "5M"
  audio_bitrate: "192k"
  preset: "fast"
  use_nvenc: true

diarization:
  enabled: false
  # Requires optional deps and a token for pyannote model downloads.
  # Set PYANNOTE_TOKEN env var when enabled.
  model: "pyannote/speaker-diarization"
